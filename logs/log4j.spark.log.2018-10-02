18/10/02 02:25:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 02:26:00 INFO SparkContext: Running Spark version 2.3.1
18/10/02 02:26:00 INFO SparkContext: Submitted application: sparklyr
18/10/02 02:26:00 INFO SecurityManager: Changing view acls to: scibr
18/10/02 02:26:00 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 02:26:00 INFO SecurityManager: Changing view acls groups to: 
18/10/02 02:26:00 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 02:26:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 02:26:00 INFO Utils: Successfully started service 'sparkDriver' on port 60000.
18/10/02 02:26:00 INFO SparkEnv: Registering MapOutputTracker
18/10/02 02:26:00 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 02:26:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 02:26:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 02:26:00 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-56f7cdb6-a8ae-4eca-9c10-6257e3cfd81d
18/10/02 02:26:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 02:26:00 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 02:26:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/10/02 02:26:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/10/02 02:26:00 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:60000/jars/sparklyr-2.3-2.11.jar with timestamp 1538414760952
18/10/02 02:26:01 INFO Executor: Starting executor ID driver on host localhost
18/10/02 02:26:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60021.
18/10/02 02:26:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:60021
18/10/02 02:26:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 02:26:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60021, None)
18/10/02 02:26:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60021 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60021, None)
18/10/02 02:26:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60021, None)
18/10/02 02:26:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60021, None)
18/10/02 02:26:01 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 02:26:01 INFO SharedState: loading hive config file: file:/C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/conf/hive-site.xml
18/10/02 02:26:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/tmp/hive').
18/10/02 02:26:01 INFO SharedState: Warehouse path is 'C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/tmp/hive'.
18/10/02 02:26:02 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/10/02 02:26:04 INFO CodeGenerator: Code generated in 233.762115 ms
18/10/02 03:05:11 INFO SparkContext: Invoking stop() from shutdown hook
18/10/02 03:05:11 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
18/10/02 03:05:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/02 03:05:11 INFO MemoryStore: MemoryStore cleared
18/10/02 03:05:11 INFO BlockManager: BlockManager stopped
18/10/02 03:05:11 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/02 03:05:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/02 03:05:11 INFO SparkContext: Successfully stopped SparkContext
18/10/02 03:05:11 INFO ShutdownHookManager: Shutdown hook called
18/10/02 03:05:11 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-76ffcf3c-58a8-4563-8163-ef91536feb1a
18/10/02 03:05:11 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-fc7b70a5-f119-451f-98e7-44573ea95c4d
18/10/02 10:22:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 10:22:51 INFO SparkContext: Running Spark version 2.3.1
18/10/02 10:22:51 INFO SparkContext: Submitted application: sparklyr
18/10/02 10:22:52 INFO SecurityManager: Changing view acls to: scibr
18/10/02 10:22:52 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 10:22:52 INFO SecurityManager: Changing view acls groups to: 
18/10/02 10:22:52 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 10:22:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 10:22:52 INFO Utils: Successfully started service 'sparkDriver' on port 61430.
18/10/02 10:22:52 INFO SparkEnv: Registering MapOutputTracker
18/10/02 10:22:52 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 10:22:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 10:22:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 10:22:52 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-cb6590f0-9389-480a-96b6-1e70b662f361
18/10/02 10:22:52 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 10:22:52 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 10:22:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
18/10/02 10:22:54 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
18/10/02 10:22:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:61430/jars/sparklyr-2.3-2.11.jar with timestamp 1538443374155
18/10/02 10:22:54 INFO Executor: Starting executor ID driver on host localhost
18/10/02 10:22:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61454.
18/10/02 10:22:54 INFO NettyBlockTransferService: Server created on 127.0.0.1:61454
18/10/02 10:22:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 10:22:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61454, None)
18/10/02 10:22:54 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61454 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61454, None)
18/10/02 10:22:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61454, None)
18/10/02 10:22:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61454, None)
18/10/02 10:22:56 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 10:22:56 INFO SharedState: loading hive config file: file:/C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/conf/hive-site.xml
18/10/02 10:22:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/tmp/hive').
18/10/02 10:22:56 INFO SharedState: Warehouse path is 'C:/Users/scibr/AppData/Local/spark/spark-2.3.1-bin-hadoop2.7/tmp/hive'.
18/10/02 10:22:58 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
18/10/02 10:23:07 INFO CodeGenerator: Code generated in 1097.279 ms
18/10/02 11:44:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 11:44:20 INFO SparkContext: Running Spark version 2.3.1
18/10/02 11:44:20 INFO SparkContext: Submitted application: sparklyr
18/10/02 11:44:20 INFO SecurityManager: Changing view acls to: scibr
18/10/02 11:44:20 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 11:44:20 INFO SecurityManager: Changing view acls groups to: 
18/10/02 11:44:20 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 11:44:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 11:44:21 INFO Utils: Successfully started service 'sparkDriver' on port 63145.
18/10/02 11:44:21 INFO SparkEnv: Registering MapOutputTracker
18/10/02 11:44:21 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 11:44:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 11:44:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 11:44:21 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-1b8690e0-64c8-4a76-99fa-0890237fae31
18/10/02 11:44:21 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 11:44:21 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 11:44:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/10/02 11:44:21 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/10/02 11:44:21 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/10/02 11:44:21 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:63145/jars/sparklyr-2.3-2.11.jar with timestamp 1538448261461
18/10/02 11:44:21 INFO Executor: Starting executor ID driver on host localhost
18/10/02 11:44:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63166.
18/10/02 11:44:21 INFO NettyBlockTransferService: Server created on 127.0.0.1:63166
18/10/02 11:44:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 11:44:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63166, None)
18/10/02 11:44:21 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63166 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63166, None)
18/10/02 11:44:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63166, None)
18/10/02 11:44:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63166, None)
18/10/02 11:44:21 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 11:44:23 INFO SparkContext: Invoking stop() from shutdown hook
18/10/02 11:44:23 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/10/02 11:44:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/02 11:44:24 INFO MemoryStore: MemoryStore cleared
18/10/02 11:44:24 INFO BlockManager: BlockManager stopped
18/10/02 11:44:24 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/02 11:44:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/02 11:44:24 INFO SparkContext: Successfully stopped SparkContext
18/10/02 11:44:24 INFO ShutdownHookManager: Shutdown hook called
18/10/02 11:44:24 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-475952f2-0861-4edc-83c8-9aeb7e25371b
18/10/02 11:44:24 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c3a33cd4-6a94-4c3d-a1f1-77fa3fb6fc01
18/10/02 11:45:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 11:45:37 INFO SparkContext: Running Spark version 2.3.1
18/10/02 11:45:37 INFO SparkContext: Submitted application: sparklyr
18/10/02 11:45:37 INFO SecurityManager: Changing view acls to: scibr
18/10/02 11:45:37 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 11:45:37 INFO SecurityManager: Changing view acls groups to: 
18/10/02 11:45:37 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 11:45:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 11:45:37 INFO Utils: Successfully started service 'sparkDriver' on port 63220.
18/10/02 11:45:37 INFO SparkEnv: Registering MapOutputTracker
18/10/02 11:45:37 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 11:45:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 11:45:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 11:45:38 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-0cd7a9e5-6983-4151-be64-93d108a2fe4f
18/10/02 11:45:38 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 11:45:38 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 11:45:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/10/02 11:45:38 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/10/02 11:45:38 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/10/02 11:45:38 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:63220/jars/sparklyr-2.3-2.11.jar with timestamp 1538448338400
18/10/02 11:45:38 INFO Executor: Starting executor ID driver on host localhost
18/10/02 11:45:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63241.
18/10/02 11:45:38 INFO NettyBlockTransferService: Server created on 127.0.0.1:63241
18/10/02 11:45:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 11:45:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63241, None)
18/10/02 11:45:38 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63241 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63241, None)
18/10/02 11:45:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63241, None)
18/10/02 11:45:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63241, None)
18/10/02 11:45:38 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 11:46:15 INFO SparkContext: Invoking stop() from shutdown hook
18/10/02 11:46:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/10/02 11:46:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/02 11:46:15 INFO MemoryStore: MemoryStore cleared
18/10/02 11:46:15 INFO BlockManager: BlockManager stopped
18/10/02 11:46:15 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/02 11:46:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/02 11:46:15 INFO SparkContext: Successfully stopped SparkContext
18/10/02 11:46:15 INFO ShutdownHookManager: Shutdown hook called
18/10/02 11:46:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-42fd3e18-849a-4f73-bc1a-d438c6c51b03
18/10/02 11:46:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-8afba716-d1cf-43c8-9515-6dbb01d7dcb2
18/10/02 21:29:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 21:29:50 INFO SparkContext: Running Spark version 2.3.1
18/10/02 21:29:50 INFO SparkContext: Submitted application: sparklyr
18/10/02 21:29:50 INFO SecurityManager: Changing view acls to: scibr
18/10/02 21:29:50 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 21:29:50 INFO SecurityManager: Changing view acls groups to: 
18/10/02 21:29:50 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 21:29:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 21:29:50 INFO Utils: Successfully started service 'sparkDriver' on port 49939.
18/10/02 21:29:50 INFO SparkEnv: Registering MapOutputTracker
18/10/02 21:29:50 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 21:29:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 21:29:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 21:29:50 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-d726f0f0-3d80-491c-8561-1a585cf3a8c1
18/10/02 21:29:50 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 21:29:50 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 21:29:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/10/02 21:29:50 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/10/02 21:29:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/10/02 21:29:51 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:49939/jars/sparklyr-2.3-2.11.jar with timestamp 1538483391126
18/10/02 21:29:51 INFO Executor: Starting executor ID driver on host localhost
18/10/02 21:29:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49960.
18/10/02 21:29:51 INFO NettyBlockTransferService: Server created on 127.0.0.1:49960
18/10/02 21:29:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 21:29:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49960, None)
18/10/02 21:29:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49960 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49960, None)
18/10/02 21:29:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49960, None)
18/10/02 21:29:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49960, None)
18/10/02 21:29:51 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 21:29:55 INFO SparkContext: Invoking stop() from shutdown hook
18/10/02 21:29:55 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/10/02 21:29:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/02 21:29:55 INFO MemoryStore: MemoryStore cleared
18/10/02 21:29:55 INFO BlockManager: BlockManager stopped
18/10/02 21:29:55 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/02 21:29:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/02 21:29:55 INFO SparkContext: Successfully stopped SparkContext
18/10/02 21:29:55 INFO ShutdownHookManager: Shutdown hook called
18/10/02 21:29:55 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-19dcf438-3412-450c-b31e-6ce686392d9d
18/10/02 21:29:55 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f1fdc32b-fa4c-4ded-844b-d09fce1828ab
18/10/02 21:39:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 21:39:14 INFO SparkContext: Running Spark version 2.3.1
18/10/02 21:39:14 INFO SparkContext: Submitted application: sparklyr
18/10/02 21:39:14 INFO SecurityManager: Changing view acls to: scibr
18/10/02 21:39:14 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 21:39:14 INFO SecurityManager: Changing view acls groups to: 
18/10/02 21:39:14 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 21:39:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 21:39:14 INFO Utils: Successfully started service 'sparkDriver' on port 50065.
18/10/02 21:39:14 INFO SparkEnv: Registering MapOutputTracker
18/10/02 21:39:14 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 21:39:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 21:39:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 21:39:14 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-79f4d741-df85-4226-9462-df0508304679
18/10/02 21:39:14 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 21:39:14 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 21:39:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/10/02 21:39:14 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/10/02 21:39:14 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/10/02 21:39:14 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:50065/jars/sparklyr-2.3-2.11.jar with timestamp 1538483954741
18/10/02 21:39:14 INFO Executor: Starting executor ID driver on host localhost
18/10/02 21:39:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50086.
18/10/02 21:39:14 INFO NettyBlockTransferService: Server created on 127.0.0.1:50086
18/10/02 21:39:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 21:39:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50086, None)
18/10/02 21:39:14 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:50086 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 50086, None)
18/10/02 21:39:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50086, None)
18/10/02 21:39:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50086, None)
18/10/02 21:39:15 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 21:39:30 INFO SparkContext: Invoking stop() from shutdown hook
18/10/02 21:39:30 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/10/02 21:39:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/02 21:39:30 INFO MemoryStore: MemoryStore cleared
18/10/02 21:39:30 INFO BlockManager: BlockManager stopped
18/10/02 21:39:30 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/02 21:39:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/02 21:39:40 WARN Executor: Issue communicating with driver in heartbeater
org.apache.spark.rpc.RpcTimeoutException: Futures timed out after [10 seconds]. This timeout is controlled by spark.executor.heartbeatInterval
	at org.apache.spark.rpc.RpcTimeout.org$apache$spark$rpc$RpcTimeout$$createRpcTimeoutException(RpcTimeout.scala:47)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:62)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:58)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:76)
	at org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:92)
	at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:785)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply$mcV$sp(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.executor.Executor$$anon$2$$anonfun$run$1.apply(Executor.scala:814)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1991)
	at org.apache.spark.executor.Executor$$anon$2.run(Executor.scala:814)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException: Futures timed out after [10 seconds]
	at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:219)
	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:223)
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:201)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	... 14 more
18/10/02 21:39:40 INFO SparkContext: Successfully stopped SparkContext
18/10/02 21:39:40 INFO ShutdownHookManager: Shutdown hook called
18/10/02 21:39:40 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-0646b0b5-d7f0-49bc-8bb9-bfe79e5784dd
18/10/02 21:39:40 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-0c719e1a-1417-4619-98b5-f29bb96d1e7e
18/10/02 21:58:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/02 21:58:57 INFO SparkContext: Running Spark version 2.3.1
18/10/02 21:58:57 INFO SparkContext: Submitted application: sparklyr
18/10/02 21:58:57 INFO SecurityManager: Changing view acls to: scibr
18/10/02 21:58:57 INFO SecurityManager: Changing modify acls to: scibr
18/10/02 21:58:57 INFO SecurityManager: Changing view acls groups to: 
18/10/02 21:58:57 INFO SecurityManager: Changing modify acls groups to: 
18/10/02 21:58:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/02 21:58:57 INFO Utils: Successfully started service 'sparkDriver' on port 50283.
18/10/02 21:58:57 INFO SparkEnv: Registering MapOutputTracker
18/10/02 21:58:57 INFO SparkEnv: Registering BlockManagerMaster
18/10/02 21:58:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/02 21:58:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/02 21:58:57 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-ed0ddaab-8295-425f-8281-4c5541a85f6a
18/10/02 21:58:57 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/02 21:58:57 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/02 21:58:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/10/02 21:58:57 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/10/02 21:58:57 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/10/02 21:58:57 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:50283/jars/sparklyr-2.3-2.11.jar with timestamp 1538485137677
18/10/02 21:58:57 INFO Executor: Starting executor ID driver on host localhost
18/10/02 21:58:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50304.
18/10/02 21:58:57 INFO NettyBlockTransferService: Server created on 127.0.0.1:50304
18/10/02 21:58:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/02 21:58:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 50304, None)
18/10/02 21:58:57 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:50304 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 50304, None)
18/10/02 21:58:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 50304, None)
18/10/02 21:58:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 50304, None)
18/10/02 21:58:58 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/02 21:59:12 INFO SparkContext: Invoking stop() from shutdown hook
18/10/02 21:59:12 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/10/02 21:59:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/02 21:59:12 INFO MemoryStore: MemoryStore cleared
18/10/02 21:59:12 INFO BlockManager: BlockManager stopped
18/10/02 21:59:12 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/02 21:59:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/02 21:59:12 INFO SparkContext: Successfully stopped SparkContext
18/10/02 21:59:12 INFO ShutdownHookManager: Shutdown hook called
18/10/02 21:59:12 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-cd966e06-8c9f-479e-8dff-186f7514130f
18/10/02 21:59:12 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-b35cd947-3426-4a04-9060-2f7ae5537296
18/10/03 01:21:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/10/03 01:21:17 INFO SparkContext: Running Spark version 2.3.1
18/10/03 01:21:17 INFO SparkContext: Submitted application: sparklyr
18/10/03 01:21:17 INFO SecurityManager: Changing view acls to: scibr
18/10/03 01:21:17 INFO SecurityManager: Changing modify acls to: scibr
18/10/03 01:21:17 INFO SecurityManager: Changing view acls groups to: 
18/10/03 01:21:17 INFO SecurityManager: Changing modify acls groups to: 
18/10/03 01:21:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
18/10/03 01:21:17 INFO Utils: Successfully started service 'sparkDriver' on port 51085.
18/10/03 01:21:17 INFO SparkEnv: Registering MapOutputTracker
18/10/03 01:21:17 INFO SparkEnv: Registering BlockManagerMaster
18/10/03 01:21:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/10/03 01:21:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/10/03 01:21:17 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-65db7d97-c7c1-4ef6-a731-d28895ffcd67
18/10/03 01:21:17 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
18/10/03 01:21:17 INFO SparkEnv: Registering OutputCommitCoordinator
18/10/03 01:21:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
18/10/03 01:21:17 INFO Utils: Successfully started service 'SparkUI' on port 4041.
18/10/03 01:21:17 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
18/10/03 01:21:17 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.5/sparklyr/java/sparklyr-2.3-2.11.jar at spark://127.0.0.1:51085/jars/sparklyr-2.3-2.11.jar with timestamp 1538497277989
18/10/03 01:21:18 INFO Executor: Starting executor ID driver on host localhost
18/10/03 01:21:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51106.
18/10/03 01:21:18 INFO NettyBlockTransferService: Server created on 127.0.0.1:51106
18/10/03 01:21:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/10/03 01:21:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51106, None)
18/10/03 01:21:18 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51106 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51106, None)
18/10/03 01:21:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51106, None)
18/10/03 01:21:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51106, None)
18/10/03 01:21:18 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
18/10/03 01:21:34 INFO SparkContext: Invoking stop() from shutdown hook
18/10/03 01:21:34 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
18/10/03 01:21:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/10/03 01:21:34 INFO MemoryStore: MemoryStore cleared
18/10/03 01:21:34 INFO BlockManager: BlockManager stopped
18/10/03 01:21:34 INFO BlockManagerMaster: BlockManagerMaster stopped
18/10/03 01:21:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/10/03 01:21:34 INFO SparkContext: Successfully stopped SparkContext
18/10/03 01:21:34 INFO ShutdownHookManager: Shutdown hook called
18/10/03 01:21:34 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-a031f94a-a7e5-4246-9b35-24348a5d9284
18/10/03 01:21:34 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-74597a5e-3bdd-48c4-bc0f-c1cd55ceed83
